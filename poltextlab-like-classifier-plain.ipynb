{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from article_dataset import ArticleDataset\n",
    "\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'major_topic_pred_index'\n",
    "ARTICLE = 'article'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=132, step=1)\n",
      "RangeIndex(start=0, stop=66, step=1)\n",
      "RangeIndex(start=0, stop=66, step=1)\n"
     ]
    }
   ],
   "source": [
    "def read_folder(folder_path):\n",
    "    dataframes = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jsonl.gz'):\n",
    "            with gzip.open(os.path.join(folder_path, filename), 'rt', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    json_data = json.loads(line)\n",
    "                    df = pd.DataFrame(json_data)\n",
    "                    dataframes.append(df)\n",
    "    if dataframes:\n",
    "        aggregated_df = pd.concat(dataframes, ignore_index=True)\n",
    "        return aggregated_df\n",
    "    else:\n",
    "        print(\"No jsonl files found in the directory.\")\n",
    "        return None\n",
    "    \n",
    "def reduce(_number=6):\n",
    "    # csak a test\n",
    "    test = os.path.join(os.getcwd(), 'test')\n",
    "    df = read_folder(test)\n",
    "    df.drop('uuid', axis=1, inplace=True)\n",
    "    return df.groupby('major_topic_pred').apply(lambda x: x.sample(n=min(_number, len(x)))).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_train = reduce()\n",
    "df_test = reduce(3)\n",
    "df_eval = reduce(3)\n",
    "\n",
    "print(df_train.index)\n",
    "print(df_test.index)\n",
    "print(df_eval.index)\n",
    "\n",
    "labels = df_train['major_topic_pred'].unique().tolist()\n",
    "number_of_labels = len(labels)\n",
    "id_to_label = {_id: label for _id, label in enumerate(labels)}\n",
    "label_to_id = {label: _id for _id, label in enumerate(labels)}\n",
    "\n",
    "\n",
    "df_train[LABEL] = df_train['major_topic_pred'].map(lambda x: label_to_id[x])\n",
    "df_test[LABEL] = df_test['major_topic_pred'].map(lambda x: label_to_id[x])\n",
    "df_eval[LABEL] = df_eval['major_topic_pred'].map(lambda x: label_to_id[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>article</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>date_of_creation</th>\n",
       "      <th>cc_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>doc_similarity</th>\n",
       "      <th>major_topic_pred</th>\n",
       "      <th>major_topic_pred_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A rendkívüli forintgyengülés repíti a Richter ...</td>\n",
       "      <td>Az elemzői várakozásokat minden szinten meghal...</td>\n",
       "      <td>Minden szinten az elemzői konszenzust felülmúl...</td>\n",
       "      <td>portfolio.hu</td>\n",
       "      <td>https://www.portfolio.hu/uzlet/20220803/a-rend...</td>\n",
       "      <td>2022-08-03T02:51:00</td>\n",
       "      <td>2022-08-10T02:11:42</td>\n",
       "      <td>gyorsjelentés,</td>\n",
       "      <td>0.860217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hatalmas deficittel birkózik az USA</td>\n",
       "      <td>Az Egyesült Államok költségvetési hiánya idén ...</td>\n",
       "      <td>A kormány költségvetési hivatala 2010-re 1,47 ...</td>\n",
       "      <td>index.hu</td>\n",
       "      <td>http://index.hu/gazdasag/vilag/2010/07/27/hata...</td>\n",
       "      <td>2010-07-27T06:53:00</td>\n",
       "      <td>2017-11-20T00:40:35</td>\n",
       "      <td>költségvetés</td>\n",
       "      <td>0.731257</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Három mûszakban dolgozik a kapuvári üzem</td>\n",
       "      <td>Kapuvár–Beled - Az utóbbi három évben több min...</td>\n",
       "      <td>Idei fejlesztéseik középpontjában a beledi üze...</td>\n",
       "      <td>kisalfold.hu</td>\n",
       "      <td>http://www.kisalfold.hu/rabakozi_hirek/harom_m...</td>\n",
       "      <td>2009-09-15T08:01:00</td>\n",
       "      <td>2017-10-19T11:23:22</td>\n",
       "      <td>Beled</td>\n",
       "      <td>0.793503</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alapos megütötték a bitcoint - Az amerikai tőz...</td>\n",
       "      <td>A hétvégi G7-csúcstalálkozó nagy adómegállapod...</td>\n",
       "      <td>2021. június 08. 22:45\\n\\nNem volt egységes ir...</td>\n",
       "      <td>portfolio.hu</td>\n",
       "      <td>https://www.portfolio.hu/uzlet/20210608/alapos...</td>\n",
       "      <td>2021-06-08T22:45:00</td>\n",
       "      <td>2021-06-15T04:20:35</td>\n",
       "      <td>részvénypiac,</td>\n",
       "      <td>0.620573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fejvesztve menekítik a magyarok a pénzüket az ...</td>\n",
       "      <td>A magas infláció miatt nagyon is érthető átren...</td>\n",
       "      <td>Számos érdekesség kirajzolódik az MNB előzetes...</td>\n",
       "      <td>portfolio.hu</td>\n",
       "      <td>https://www.portfolio.hu/befektetes/20230518/f...</td>\n",
       "      <td>2023-05-18T10:59:00</td>\n",
       "      <td>2023-05-31T00:22:17</td>\n",
       "      <td>befektetési alap,</td>\n",
       "      <td>0.682144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  A rendkívüli forintgyengülés repíti a Richter ...   \n",
       "1                Hatalmas deficittel birkózik az USA   \n",
       "2           Három mûszakban dolgozik a kapuvári üzem   \n",
       "3  Alapos megütötték a bitcoint - Az amerikai tőz...   \n",
       "4  Fejvesztve menekítik a magyarok a pénzüket az ...   \n",
       "\n",
       "                                                lead  \\\n",
       "0  Az elemzői várakozásokat minden szinten meghal...   \n",
       "1  Az Egyesült Államok költségvetési hiánya idén ...   \n",
       "2  Kapuvár–Beled - Az utóbbi három évben több min...   \n",
       "3  A hétvégi G7-csúcstalálkozó nagy adómegállapod...   \n",
       "4  A magas infláció miatt nagyon is érthető átren...   \n",
       "\n",
       "                                             article        domain  \\\n",
       "0  Minden szinten az elemzői konszenzust felülmúl...  portfolio.hu   \n",
       "1  A kormány költségvetési hivatala 2010-re 1,47 ...      index.hu   \n",
       "2  Idei fejlesztéseik középpontjában a beledi üze...  kisalfold.hu   \n",
       "3  2021. június 08. 22:45\\n\\nNem volt egységes ir...  portfolio.hu   \n",
       "4  Számos érdekesség kirajzolódik az MNB előzetes...  portfolio.hu   \n",
       "\n",
       "                                                 url     date_of_creation  \\\n",
       "0  https://www.portfolio.hu/uzlet/20220803/a-rend...  2022-08-03T02:51:00   \n",
       "1  http://index.hu/gazdasag/vilag/2010/07/27/hata...  2010-07-27T06:53:00   \n",
       "2  http://www.kisalfold.hu/rabakozi_hirek/harom_m...  2009-09-15T08:01:00   \n",
       "3  https://www.portfolio.hu/uzlet/20210608/alapos...  2021-06-08T22:45:00   \n",
       "4  https://www.portfolio.hu/befektetes/20230518/f...  2023-05-18T10:59:00   \n",
       "\n",
       "               cc_date               tags  doc_similarity  major_topic_pred  \\\n",
       "0  2022-08-10T02:11:42     gyorsjelentés,        0.860217                 1   \n",
       "1  2017-11-20T00:40:35       költségvetés        0.731257                 1   \n",
       "2  2017-10-19T11:23:22              Beled        0.793503                 1   \n",
       "3  2021-06-15T04:20:35      részvénypiac,        0.620573                 1   \n",
       "4  2023-05-31T00:22:17  befektetési alap,        0.682144                 1   \n",
       "\n",
       "   major_topic_pred_index  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>article</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>date_of_creation</th>\n",
       "      <th>cc_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>doc_similarity</th>\n",
       "      <th>major_topic_pred</th>\n",
       "      <th>major_topic_pred_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Galambos Lajos nagyon lefogyott – ez a szilves...</td>\n",
       "      <td>Minden csatorna készül valami szilveszteri műs...</td>\n",
       "      <td>Még ősszel mesélt Galambos Lajos arról, hogy f...</td>\n",
       "      <td>nlc.hu</td>\n",
       "      <td>https://nlc.hu/sztarok/20201229/galambos-lajos...</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-02-25T11:25:37</td>\n",
       "      <td>Galambos Lajos Lagzi Lajcsi Life TV szilveszte...</td>\n",
       "      <td>0.206171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hogyan játsszuk ki a vagyonellenőrzést?</td>\n",
       "      <td>Alkotmányellenes és nemzetközi megállapodásba ...</td>\n",
       "      <td>\"A téma mindannyiunkat érintő ügy\" – mondta ál...</td>\n",
       "      <td>index.hu</td>\n",
       "      <td>https://index.hu/gazdasag/magyar/vgyn070312/</td>\n",
       "      <td>2007-03-12T14:18:00</td>\n",
       "      <td>2021-01-22T23:10:10</td>\n",
       "      <td>Magyar</td>\n",
       "      <td>0.649183</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Az adósságcsökkentés apasztotta a devizatartal...</td>\n",
       "      <td>A majdnem kétmilliárd euró értékű kötvénytarto...</td>\n",
       "      <td>A tartalékok csökkenését az magyarázza, hogy j...</td>\n",
       "      <td>origo.hu</td>\n",
       "      <td>https://www.origo.hu/gazdasag/20200211-adossag...</td>\n",
       "      <td>2020-02-11T11:35:00</td>\n",
       "      <td>2022-08-10T19:41:00</td>\n",
       "      <td>devizatartalék</td>\n",
       "      <td>0.717533</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Szaúd-Arábiában bebörtönzött nőjogi aktivisták...</td>\n",
       "      <td>A társadalmi helyzetükre vonatkozó sztereotípi...</td>\n",
       "      <td>A szaúdi hatóságok több mint egy tucat nőjogi ...</td>\n",
       "      <td>bama.hu</td>\n",
       "      <td>https://www.bama.hu/orszag-vilag/szaud-arabiab...</td>\n",
       "      <td>2018-10-12T16:44:00</td>\n",
       "      <td>2019-06-26T21:56:38</td>\n",
       "      <td>halálbüntetés</td>\n",
       "      <td>0.470580</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diszkriminációról beszélnek a repülõrõl leszál...</td>\n",
       "      <td>Egy duplán eladott ülés miatt alakult ki a vit...</td>\n",
       "      <td>Több utast leszállítottak a Spirit Airlines Lo...</td>\n",
       "      <td>origo.hu</td>\n",
       "      <td>https://www.origo.hu/utazas/20151103-diszkrimi...</td>\n",
       "      <td>2015-11-03T14:15:00</td>\n",
       "      <td>2019-11-18T17:01:27</td>\n",
       "      <td>utazás</td>\n",
       "      <td>0.396952</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Galambos Lajos nagyon lefogyott – ez a szilves...   \n",
       "1            Hogyan játsszuk ki a vagyonellenőrzést?   \n",
       "2  Az adósságcsökkentés apasztotta a devizatartal...   \n",
       "3  Szaúd-Arábiában bebörtönzött nőjogi aktivisták...   \n",
       "4  Diszkriminációról beszélnek a repülõrõl leszál...   \n",
       "\n",
       "                                                lead  \\\n",
       "0  Minden csatorna készül valami szilveszteri műs...   \n",
       "1  Alkotmányellenes és nemzetközi megállapodásba ...   \n",
       "2  A majdnem kétmilliárd euró értékű kötvénytarto...   \n",
       "3  A társadalmi helyzetükre vonatkozó sztereotípi...   \n",
       "4  Egy duplán eladott ülés miatt alakult ki a vit...   \n",
       "\n",
       "                                             article    domain  \\\n",
       "0  Még ősszel mesélt Galambos Lajos arról, hogy f...    nlc.hu   \n",
       "1  \"A téma mindannyiunkat érintő ügy\" – mondta ál...  index.hu   \n",
       "2  A tartalékok csökkenését az magyarázza, hogy j...  origo.hu   \n",
       "3  A szaúdi hatóságok több mint egy tucat nőjogi ...   bama.hu   \n",
       "4  Több utast leszállítottak a Spirit Airlines Lo...  origo.hu   \n",
       "\n",
       "                                                 url     date_of_creation  \\\n",
       "0  https://nlc.hu/sztarok/20201229/galambos-lajos...                 None   \n",
       "1       https://index.hu/gazdasag/magyar/vgyn070312/  2007-03-12T14:18:00   \n",
       "2  https://www.origo.hu/gazdasag/20200211-adossag...  2020-02-11T11:35:00   \n",
       "3  https://www.bama.hu/orszag-vilag/szaud-arabiab...  2018-10-12T16:44:00   \n",
       "4  https://www.origo.hu/utazas/20151103-diszkrimi...  2015-11-03T14:15:00   \n",
       "\n",
       "               cc_date                                               tags  \\\n",
       "0  2021-02-25T11:25:37  Galambos Lajos Lagzi Lajcsi Life TV szilveszte...   \n",
       "1  2021-01-22T23:10:10                                             Magyar   \n",
       "2  2022-08-10T19:41:00                                     devizatartalék   \n",
       "3  2019-06-26T21:56:38                                      halálbüntetés   \n",
       "4  2019-11-18T17:01:27                                             utazás   \n",
       "\n",
       "   doc_similarity  major_topic_pred  major_topic_pred_index  \n",
       "0        0.206171                 1                       0  \n",
       "1        0.649183                 1                       0  \n",
       "2        0.717533                 1                       0  \n",
       "3        0.470580                 2                       1  \n",
       "4        0.396952                 2                       1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>article</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>date_of_creation</th>\n",
       "      <th>cc_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>doc_similarity</th>\n",
       "      <th>major_topic_pred</th>\n",
       "      <th>major_topic_pred_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Felére csökkent a Volkswagen nyeresége</td>\n",
       "      <td>A Volkswagen harmadik negyedéves nyeresége köz...</td>\n",
       "      <td>A gyár nettó profitja 439 millió euróra csökke...</td>\n",
       "      <td>origo.hu</td>\n",
       "      <td>https://www.origo.hu/gazdasag/hirek/20021030fe...</td>\n",
       "      <td>2002-10-30T11:07:00</td>\n",
       "      <td>2019-05-27T12:36:13</td>\n",
       "      <td>Volkswagen AG</td>\n",
       "      <td>0.823234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L. Simon: Nem az RTL Klub ellen van a reklámtö...</td>\n",
       "      <td>Az internetes tartalomszolgáltatók adóköteleze...</td>\n",
       "      <td>A reklámtörvénnyel kapcsolatban az internetes ...</td>\n",
       "      <td>hvg.hu</td>\n",
       "      <td>https://hvg.hu/gazdasag/20140805_L_Simon_nem_a...</td>\n",
       "      <td>2014-08-05T05:29:00</td>\n",
       "      <td>2021-04-21T22:57:05</td>\n",
       "      <td>L. Simon László</td>\n",
       "      <td>0.825578</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Európába jött a mindent verő új Tesla Roadster</td>\n",
       "      <td>Az első példány hófehér fényezéssel érkezett m...</td>\n",
       "      <td>A Tesla nagyot durrantott azzal, hogy tavaly n...</td>\n",
       "      <td>hvg.hu</td>\n",
       "      <td>https://hvg.hu/cegauto/20180907_europaba_jott_...</td>\n",
       "      <td>2018-09-07T11:21:00</td>\n",
       "      <td>2020-12-05T12:38:34</td>\n",
       "      <td>e-autó</td>\n",
       "      <td>0.181144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nem nézett rá a megtámadott cigány asszony a r...</td>\n",
       "      <td>Először találkozhattak a cigányok elleni támad...</td>\n",
       "      <td>A cigányok elleni támadássorozat első roma sér...</td>\n",
       "      <td>origo.hu</td>\n",
       "      <td>https://www.origo.hu/itthon/20110518-nem-nezet...</td>\n",
       "      <td>2011-05-18T11:10:00</td>\n",
       "      <td>2022-11-28T01:54:23</td>\n",
       "      <td>cigányok elleni támadások</td>\n",
       "      <td>0.647014</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A spárga és a kucsmagomba szerelme</td>\n",
       "      <td>Ahogy a legjobb zsidóvicceket mindig zsidók mo...</td>\n",
       "      <td>Melegviccekben erősen nyit a moziév. Guy Ritch...</td>\n",
       "      <td>index.hu</td>\n",
       "      <td>http://index.hu/kultur/cinematrix/kritika/mele...</td>\n",
       "      <td>2009-01-05T11:15:00</td>\n",
       "      <td>2017-12-13T10:10:59</td>\n",
       "      <td>Kritika</td>\n",
       "      <td>0.408078</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0             Felére csökkent a Volkswagen nyeresége   \n",
       "1  L. Simon: Nem az RTL Klub ellen van a reklámtö...   \n",
       "2     Európába jött a mindent verő új Tesla Roadster   \n",
       "3  Nem nézett rá a megtámadott cigány asszony a r...   \n",
       "4                 A spárga és a kucsmagomba szerelme   \n",
       "\n",
       "                                                lead  \\\n",
       "0  A Volkswagen harmadik negyedéves nyeresége köz...   \n",
       "1  Az internetes tartalomszolgáltatók adóköteleze...   \n",
       "2  Az első példány hófehér fényezéssel érkezett m...   \n",
       "3  Először találkozhattak a cigányok elleni támad...   \n",
       "4  Ahogy a legjobb zsidóvicceket mindig zsidók mo...   \n",
       "\n",
       "                                             article    domain  \\\n",
       "0  A gyár nettó profitja 439 millió euróra csökke...  origo.hu   \n",
       "1  A reklámtörvénnyel kapcsolatban az internetes ...    hvg.hu   \n",
       "2  A Tesla nagyot durrantott azzal, hogy tavaly n...    hvg.hu   \n",
       "3  A cigányok elleni támadássorozat első roma sér...  origo.hu   \n",
       "4  Melegviccekben erősen nyit a moziév. Guy Ritch...  index.hu   \n",
       "\n",
       "                                                 url     date_of_creation  \\\n",
       "0  https://www.origo.hu/gazdasag/hirek/20021030fe...  2002-10-30T11:07:00   \n",
       "1  https://hvg.hu/gazdasag/20140805_L_Simon_nem_a...  2014-08-05T05:29:00   \n",
       "2  https://hvg.hu/cegauto/20180907_europaba_jott_...  2018-09-07T11:21:00   \n",
       "3  https://www.origo.hu/itthon/20110518-nem-nezet...  2011-05-18T11:10:00   \n",
       "4  http://index.hu/kultur/cinematrix/kritika/mele...  2009-01-05T11:15:00   \n",
       "\n",
       "               cc_date                       tags  doc_similarity  \\\n",
       "0  2019-05-27T12:36:13              Volkswagen AG        0.823234   \n",
       "1  2021-04-21T22:57:05            L. Simon László        0.825578   \n",
       "2  2020-12-05T12:38:34                     e-autó        0.181144   \n",
       "3  2022-11-28T01:54:23  cigányok elleni támadások        0.647014   \n",
       "4  2017-12-13T10:10:59                    Kritika        0.408078   \n",
       "\n",
       "   major_topic_pred  major_topic_pred_index  \n",
       "0                 1                       0  \n",
       "1                 1                       0  \n",
       "2                 1                       0  \n",
       "3                 2                       1  \n",
       "4                 2                       1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 1,\n",
       "  1: 2,\n",
       "  2: 3,\n",
       "  3: 4,\n",
       "  4: 5,\n",
       "  5: 6,\n",
       "  6: 7,\n",
       "  7: 8,\n",
       "  8: 9,\n",
       "  9: 10,\n",
       "  10: 12,\n",
       "  11: 13,\n",
       "  12: 14,\n",
       "  13: 15,\n",
       "  14: 16,\n",
       "  15: 17,\n",
       "  16: 18,\n",
       "  17: 19,\n",
       "  18: 20,\n",
       "  19: 21,\n",
       "  20: 23,\n",
       "  21: 999},\n",
       " {1: 0,\n",
       "  2: 1,\n",
       "  3: 2,\n",
       "  4: 3,\n",
       "  5: 4,\n",
       "  6: 5,\n",
       "  7: 6,\n",
       "  8: 7,\n",
       "  9: 8,\n",
       "  10: 9,\n",
       "  12: 10,\n",
       "  13: 11,\n",
       "  14: 12,\n",
       "  15: 13,\n",
       "  16: 14,\n",
       "  17: 15,\n",
       "  18: 16,\n",
       "  19: 17,\n",
       "  20: 18,\n",
       "  21: 19,\n",
       "  23: 20,\n",
       "  999: 21})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label, label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minden szinten az elemzői konszenzust felülmúló második negyedéves eredményekről számolt be ma hajnalban közzétett gyorsjelentésében a Richter. A bevétel és az adózott eredmény új negyedéves rekordot állított fel, a profit a legoptimistább elemzői várakozásokat is meghaladta.\n",
      "Az erős negyedévhez a cég számára kedvező devizaárfolyam-környezet, a forintgyengülés, a specializált termékek stabil növekedése és egy egyszeri mérföldkő-bevétel is hozzájárult.\n",
      "A lezárt negyedév eredményei mellett legalább olyan fontos, hogy mit mond a menedzsment a kilátásokkal kapcsolatban. A cégvezetés februárban, az orosz-ukrán háború kitörését követően pesszimistább lett az idei évre, egy nemrégiben adott interjúban azonban Orbán Gábor már optimistább volt, nyilatkozata szerint olyan helyzetben van a Richter, hogy teljesíteni tudja az eredeti üzleti tervet. (Eredetileg a vállalat forintban kifejezve 10 százalékos bevétel-és nyereségnövekedést célzott meg 2022-re.)\n",
      "A világgazdasági környezetben tapasztalható kihívások ellenére is kitartunk mind a 2022-ben kitűzött pénzügyi célok, mind pedig a fejlesztési fázisban lévő projektjeink előmozdítása mellett\n",
      "– olvasható Orbán Gábor vezérigazgató kommentárja a gyorsjelentésben.\n",
      "Közel 24 százalékkal emelkedett a második negyedévben a Richter bevétele, meghaladva a 192 milliárd forintot, ami egyben új negyedéves rekordot is jelent.\n",
      "A bruttó fedezeti hányad javult a második negyedévben az egy ével ezelőtti szintről, részben annak köszönhetően, hogy a gyógyszergyártási tevékenység árbevétel növekedése meghaladta az alacsony fedezetű nagy- és kiskereskedelmi szegmens forgalmának bővülését.\n",
      "A fedezetet pozitívan befolyásolta a cég számára kedvező árfolyamkörnyezet, a jelentősen gyengülő forint, valamint az euróval szemben erősödő dollár és rubel árfolyam. Szintén felfelé segítette a Vraylar amerikai értékesítése után járó royalty növekedése, valamint egyes tradicionális és nőgyógyászati termékek, mint a hormonális fogamzásgátlók, a Bromocriptin és a Bemfola árbevételének növekedése. Negatívan hatott közben a termékelőállítási költségek inflációs növekedése és a bruttó fedezeti hányadot az Evra is kismértékben csökkentette.\n",
      "A kutatás-fejlesztési költségek nagyot emelkedtek a negyedévben, meghaladták az árbevétel 10 százalékát. Ezen költségek szintjét elsősorban az AbbVie-val közösen végzett, jelenleg is folyó klinikai vizsgálatok, valamint a biotechnológiai és nőgyógyászati fejlesztési programok magyarázzák. A k+f költségeket növelték egyes központi idegrendszeri projektek is, amelyek sikeresen klinikai fázisba értek.\n",
      "2022 első félévében az üzleti tevékenység eredménye jelentősen növekedett a bázisidőszakban elért értékhez képest, amire a rendkívüli árfolyamkörnyezet, valamint a beszámolási időszakban jóváírt egyszeri mérföldkő bevétel gyakorolt jelentős hatást. 2022 első félévében összesen 8,63 milliárd forint értékben számolt el mérföldkő bevételt a Richter, amiből a második negyedévben 8,616 milliárd forintot (25 millió USD) az AbbVie fizetett a két cég között 2022 márciusában létrejött, a neuropszichiátriai betegségekre kiterjedő együttműködéshez, illetve a cariprazine MDD indikációra vonatkozó törzskönyvi kérelem-kiegészítés FDA által történő befogadásához kapcsolódóan.\n",
      "A negyedéves nettó eredmény megugrását segítette, hogy pénzügyi eredmény soron ezúttal jelentős, 28,7 milliárd forintos pozitív eredményt könyvelt el a Richter a második negyedévben.\n",
      "Az adózott eredmény szintjén 76,5 milliárd forintos nyereséggel zárta a második negyedévet a Richter, ami több mint a két és félszerese az egy évvel korábbinak.\n",
      "A Richter egyik húzóterméke, a Vraylar a második negyedévben is hozzájárult a bevételek növekedéséhez. A készítménnyel kapcsolatos fejlemény, hogy a kedvező fázis III vizsgálatok eredményei fényében 2022 első negyedévében a Richter amerikai partnere, az AbbVie kiegészítő engedélykérelmet nyújtott be az Egyesült Államok Élelmiszer és Gyógyszerügyi Hivatalához, hogy a cariprazine használatát kiterjesszék a major depresszió kiegészítő kezelésére, melyet késő áprilisban be is fogadtak felülvizsgálatra. Emellett április végén a Kanadai Egészségügyi Hatóság engedélyezte a felnőttek számára a Vraylar monoterápiában történő alkalmazását az I. típusú bipoláris betegség mániás, kevert és depressziós epizódjainak akut kezelésére, továbbá a skizofrénia kezelésére szintén felnőttek számára.\n",
      "A stratégiai nőgyógyászati üzletágban az év első felében Nyugat-Európában, Oroszországban, az Egyesült Államokban, Közép-Kelet-Európában, Latin-Amerikában és Kínában elért forgalom növekedést részben mérsékelte az Ukrajnában bekövetkezett forgalomcsökkenés. A nőgyógyászati termékcsoport forgalma elsősorban az orális fogamzásgátlók árbevételének, illetve a tavaly januárban felvásárolt Evra fogamzásgátló tapasz értékesítés után elszámolt royalty és termékértékesítési forgalmának köszönhetően emelkedett. Az árbevétel alakulását nagymértékben befolyásolta a Drovelis 2021 második negyedévében bekövetkezett piaci bevezetése, ezen túl pedig a sürgősségi fogamzásgátló Plan B értékesítése tovább növelte az USA-ban elért forgalmat – áll a Richter gyorsjelentésében.\n",
      "A bioszimiláris portfóliónak egyre nagyobb a súlya a bevételekben, a teriparatide árbevétele az év első hat hónapjában közel 60 százalékkal nőtt.\n",
      "Tavasszal az orosz-ukrán háború kirobbanását követő részvénypiaci lejtmenet alól a Richter részvényei sem tudták magukat kivonni, az elmúlt egy hónapban azonban – különösen a menedzsment optimistább nyilatkozatait követően – magára talált az árfolyam.\n",
      "Bár még így is közel 9 százalékot esett idén a részvény, az értékeltségi szintek elindultak felfelé, az előretekintő P/E ráta ismét kétszámjegyű. Ez azonban még mindig elmarad a hosszú távú átlagtól, ami 14-szeres.\n",
      "A legközelebbi szektortársakhoz viszonyított diszkont, ami már évek óta jellemzi a Richter részvényeit, továbbra is fennáll, sőt, 2021/2022 során korábban nem látott mértékűre duzzadt.\n",
      "Előretekintő P/E ráta alapján, a növekedési várakozások fényében olcsónak számítanak jelenleg a Richter részvényei a legközelebbi szektortársakhoz és a nagy európai gyógyszercégekhez viszonyítva is.\n",
      "EV/EBITDA ráta tekintetében szintén alulértékeltnek tűnnek jelenleg a Richter papírjai a peer grouphoz viszonyítva.\n",
      "A Richter részvényeire vonatkozó célárak csökkentek idén, de a medián célár még mindig magasabban áll, mint a Richter jelenlegi árfolyama, vagyis felértékelődési potenciált látnak a papírban a vállalatot követő elemzők.\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "sample_row = df_train.iloc[0]\n",
    "sample_article = sample_row[ARTICLE]\n",
    "sample_label = sample_row[LABEL]\n",
    "\n",
    "print(sample_article)\n",
    "print(\"label: \", sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_article,\n",
    "  add_special_tokens=True,\n",
    "  max_length=1024,\n",
    "  return_token_type_ids=False,\n",
    "  padding=\"max_length\",\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2525]), torch.Size([1, 2525]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[\"input_ids\"].shape, encoding[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'mind', '##en', 's', '##zin', '##ten', 'az', 'el', '##em', '##zo', '##i', 'ko', '##ns', '##zen', '##zu', '##st', 'fe', '##lu', '##lm', '##ulo']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"].squeeze())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = []\n",
    "\n",
    "for _, row in df_train.iterrows():\n",
    "    token_count = len(tokenizer.encode(\n",
    "        row[ARTICLE], \n",
    "        max_length=512, \n",
    "        truncation=True\n",
    "    ))\n",
    "    token_counts.append(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(token_counts)\n",
    "plt.xlim([0, 512]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['article', 'input_ids', 'attention_mask', 'label'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dataset = ArticleDataset(\n",
    "  df_train,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "sample_item = train_dataset[0]\n",
    "sample_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': 'Minden szinten az elemzői konszenzust felülmúló második negyedéves eredményekről számolt be ma hajnalban közzétett gyorsjelentésében a Richter. A bevétel és az adózott eredmény új negyedéves rekordot állított fel, a profit a legoptimistább elemzői várakozásokat is meghaladta.\\nAz erős negyedévhez a cég számára kedvező devizaárfolyam-környezet, a forintgyengülés, a specializált termékek stabil növekedése és egy egyszeri mérföldkő-bevétel is hozzájárult.\\nA lezárt negyedév eredményei mellett legalább olyan fontos, hogy mit mond a menedzsment a kilátásokkal kapcsolatban. A cégvezetés februárban, az orosz-ukrán háború kitörését követően pesszimistább lett az idei évre, egy nemrégiben adott interjúban azonban Orbán Gábor már optimistább volt, nyilatkozata szerint olyan helyzetben van a Richter, hogy teljesíteni tudja az eredeti üzleti tervet. (Eredetileg a vállalat forintban kifejezve 10 százalékos bevétel-és nyereségnövekedést célzott meg 2022-re.)\\nA világgazdasági környezetben tapasztalható kihívások ellenére is kitartunk mind a 2022-ben kitűzött pénzügyi célok, mind pedig a fejlesztési fázisban lévő projektjeink előmozdítása mellett\\n– olvasható Orbán Gábor vezérigazgató kommentárja a gyorsjelentésben.\\nKözel 24 százalékkal emelkedett a második negyedévben a Richter bevétele, meghaladva a 192 milliárd forintot, ami egyben új negyedéves rekordot is jelent.\\nA bruttó fedezeti hányad javult a második negyedévben az egy ével ezelőtti szintről, részben annak köszönhetően, hogy a gyógyszergyártási tevékenység árbevétel növekedése meghaladta az alacsony fedezetű nagy- és kiskereskedelmi szegmens forgalmának bővülését.\\nA fedezetet pozitívan befolyásolta a cég számára kedvező árfolyamkörnyezet, a jelentősen gyengülő forint, valamint az euróval szemben erősödő dollár és rubel árfolyam. Szintén felfelé segítette a Vraylar amerikai értékesítése után járó royalty növekedése, valamint egyes tradicionális és nőgyógyászati termékek, mint a hormonális fogamzásgátlók, a Bromocriptin és a Bemfola árbevételének növekedése. Negatívan hatott közben a termékelőállítási költségek inflációs növekedése és a bruttó fedezeti hányadot az Evra is kismértékben csökkentette.\\nA kutatás-fejlesztési költségek nagyot emelkedtek a negyedévben, meghaladták az árbevétel 10 százalékát. Ezen költségek szintjét elsősorban az AbbVie-val közösen végzett, jelenleg is folyó klinikai vizsgálatok, valamint a biotechnológiai és nőgyógyászati fejlesztési programok magyarázzák. A k+f költségeket növelték egyes központi idegrendszeri projektek is, amelyek sikeresen klinikai fázisba értek.\\n2022 első félévében az üzleti tevékenység eredménye jelentősen növekedett a bázisidőszakban elért értékhez képest, amire a rendkívüli árfolyamkörnyezet, valamint a beszámolási időszakban jóváírt egyszeri mérföldkő bevétel gyakorolt jelentős hatást. 2022 első félévében összesen 8,63 milliárd forint értékben számolt el mérföldkő bevételt a Richter, amiből a második negyedévben 8,616 milliárd forintot (25 millió USD) az AbbVie fizetett a két cég között 2022 márciusában létrejött, a neuropszichiátriai betegségekre kiterjedő együttműködéshez, illetve a cariprazine MDD indikációra vonatkozó törzskönyvi kérelem-kiegészítés FDA által történő befogadásához kapcsolódóan.\\nA negyedéves nettó eredmény megugrását segítette, hogy pénzügyi eredmény soron ezúttal jelentős, 28,7 milliárd forintos pozitív eredményt könyvelt el a Richter a második negyedévben.\\nAz adózott eredmény szintjén 76,5 milliárd forintos nyereséggel zárta a második negyedévet a Richter, ami több mint a két és félszerese az egy évvel korábbinak.\\nA Richter egyik húzóterméke, a Vraylar a második negyedévben is hozzájárult a bevételek növekedéséhez. A készítménnyel kapcsolatos fejlemény, hogy a kedvező fázis III vizsgálatok eredményei fényében 2022 első negyedévében a Richter amerikai partnere, az AbbVie kiegészítő engedélykérelmet nyújtott be az Egyesült Államok Élelmiszer és Gyógyszerügyi Hivatalához, hogy a cariprazine használatát kiterjesszék a major depresszió kiegészítő kezelésére, melyet késő áprilisban be is fogadtak felülvizsgálatra. Emellett április végén a Kanadai Egészségügyi Hatóság engedélyezte a felnőttek számára a Vraylar monoterápiában történő alkalmazását az I. típusú bipoláris betegség mániás, kevert és depressziós epizódjainak akut kezelésére, továbbá a skizofrénia kezelésére szintén felnőttek számára.\\nA stratégiai nőgyógyászati üzletágban az év első felében Nyugat-Európában, Oroszországban, az Egyesült Államokban, Közép-Kelet-Európában, Latin-Amerikában és Kínában elért forgalom növekedést részben mérsékelte az Ukrajnában bekövetkezett forgalomcsökkenés. A nőgyógyászati termékcsoport forgalma elsősorban az orális fogamzásgátlók árbevételének, illetve a tavaly januárban felvásárolt Evra fogamzásgátló tapasz értékesítés után elszámolt royalty és termékértékesítési forgalmának köszönhetően emelkedett. Az árbevétel alakulását nagymértékben befolyásolta a Drovelis 2021 második negyedévében bekövetkezett piaci bevezetése, ezen túl pedig a sürgősségi fogamzásgátló Plan B értékesítése tovább növelte az USA-ban elért forgalmat – áll a Richter gyorsjelentésében.\\nA bioszimiláris portfóliónak egyre nagyobb a súlya a bevételekben, a teriparatide árbevétele az év első hat hónapjában közel 60 százalékkal nőtt.\\nTavasszal az orosz-ukrán háború kirobbanását követő részvénypiaci lejtmenet alól a Richter részvényei sem tudták magukat kivonni, az elmúlt egy hónapban azonban – különösen a menedzsment optimistább nyilatkozatait követően – magára talált az árfolyam.\\nBár még így is közel 9 százalékot esett idén a részvény, az értékeltségi szintek elindultak felfelé, az előretekintő P/E ráta ismét kétszámjegyű. Ez azonban még mindig elmarad a hosszú távú átlagtól, ami 14-szeres.\\nA legközelebbi szektortársakhoz viszonyított diszkont, ami már évek óta jellemzi a Richter részvényeit, továbbra is fennáll, sőt, 2021/2022 során korábban nem látott mértékűre duzzadt.\\nElőretekintő P/E ráta alapján, a növekedési várakozások fényében olcsónak számítanak jelenleg a Richter részvényei a legközelebbi szektortársakhoz és a nagy európai gyógyszercégekhez viszonyítva is.\\nEV/EBITDA ráta tekintetében szintén alulértékeltnek tűnnek jelenleg a Richter papírjai a peer grouphoz viszonyítva.\\nA Richter részvényeire vonatkozó célárak csökkentek idén, de a medián célár még mindig magasabban áll, mint a Richter jelenlegi árfolyama, vagyis felértékelődési potenciált látnak a papírban a vállalatot követő elemzők.',\n",
       " 'input_ids': tensor([  101,  2568,  2368,  1055, 17168,  6528, 17207,  3449,  6633,  6844,\n",
       "          2072, 12849,  3619, 10431,  9759,  3367, 10768,  7630, 13728, 18845,\n",
       "         16137,  7716,  5480, 11265,  6292, 14728,  6961,  9413,  2098,  3549,\n",
       "          6672, 21638,  4747,  1055, 20722, 27914,  2022,  5003,  5292, 22895,\n",
       "          2389,  8193, 12849, 13213, 12870,  4779,  1043,  7677,  2869,  6460,\n",
       "         16136,  6810, 10609,  1037, 20105,  1012,  1037,  2022, 19510,  2884,\n",
       "          9686, 17207,  4748, 18153, 14517,  9413,  2098,  3549,  2100,  1057,\n",
       "          3501, 11265,  6292, 14728,  6961,  2128, 21815, 27364,  2035,  9956,\n",
       "          4779, 10768,  2140,  1010,  1037,  5618,  1037, 23853, 13876, 27605,\n",
       "          9153, 10322,  3449,  6633,  6844,  2072, 13075, 20411,  4143,  6499,\n",
       "         24498,  2003, 12669, 19531, 11927,  2050,  1012, 17207,  9413,  2891,\n",
       "         11265,  6292, 14728,  2615,  5369,  2480,  1037,  8292,  2290,  1055,\n",
       "         20722,  5400, 16135, 26132,  2080, 14386,  4143,  2906, 14876,  2135,\n",
       "          3286,  1011, 12849,  6826,  6672,  4371,  2102,  1010,  1037,  2005,\n",
       "         18447,  6292, 13159, 16308,  1010,  1037,  2569, 21335,  7096,  2744,\n",
       "         23941,  2243, 17079,  4014, 13292, 23941,  6155,  2063,  9686,  1041,\n",
       "          6292,  1041,  6292, 17112, 11124, 21442, 10371,  3683,  1011,  2022,\n",
       "         19510,  2884,  2003,  7570, 20715, 16084, 11314,  1012,  1037,  3393,\n",
       "          9057,  2102, 11265,  6292, 14728,  2615,  9413,  2098,  3549,  6672,\n",
       "          2072, 11463, 20897,  3423,  7875,  2497, 19330,  7054, 15489,  2891,\n",
       "          1010, 27589,  2100, 10210, 12256,  2094,  1037,  2273,  2098,  2480,\n",
       "          6491,  4765,  1037, 11382, 20051,  3022,  6559, 12902, 10556, 15042,\n",
       "         19454,  4017,  8193,  1012,  1037,  8292,  2290, 26132, 12870,  2015,\n",
       "         13114,  6820,  2906,  8193,  1010, 17207, 20298, 17112,  1011,  2866,\n",
       "          5521,  5292, 12821,  2226,  8934, 16610,  3388, 12849, 19510,  8913,\n",
       "          2078, 21877,  4757,  5831, 23738,  7875,  2497,  2292,  2102, 17207,\n",
       "          8909,  7416, 23408,  2890,  1010,  1041,  6292, 11265,  2213,  2890,\n",
       "          5856, 10609,  4748, 14517,  6970,  9103,  8193, 17207,  2239,  8193,\n",
       "         19607,  2319, 11721, 12821,  9388, 23569, 27605,  9153, 10322,  5285,\n",
       "          2102,  1010,  6396, 11733,  2102,  3683,  4143,  2696,  1055,  6290,\n",
       "         18447, 19330,  7054,  2002,  2135,  4371,  2102, 10609,  3158,  1037,\n",
       "         20105,  1010, 27589,  2100, 10093,  6460, 28032, 18595, 10722,  2094,\n",
       "          3900, 17207,  9413, 14728,  3775,  1057, 29247,  3775, 28774, 19510,\n",
       "          1012,  1006,  9413, 14728, 15286,  2290,  1037, 11748, 13837,  4017,\n",
       "          2005, 18447,  8193, 11382,  7959,  6460,  2480,  3726,  2184,  1055,\n",
       "          4143, 16739,  5937,  2891,  2022, 19510,  2884,  1011,  9686,  6396,\n",
       "         18702, 13910, 16693, 23941,  6155,  2102,  8292, 23858, 14517, 12669,\n",
       "         16798,  2475,  1011,  2128,  1012,  1007,  1037, 23840, 23033, 26494,\n",
       "         16782,  5856, 12849,  6826,  6672,  4371,  2102, 10609, 11112,  3022,\n",
       "          2480,  9080, 12707,  2080, 11382,  4048, 12044,  6559,  9155,  7869,\n",
       "          2003,  8934,  8445, 16814,  2568,  1037, 16798,  2475,  1011,  3841,\n",
       "          8934, 17040, 14517,  7279,  9759,  6292,  2072,  8292, 29027,  1010,\n",
       "          2568, 21877,  4305,  2290,  1037, 10768,  3501,  4244,  2480,  4570,\n",
       "          2072,  6904,  5831, 19022,  2319, 23310,  2080,  4013,  6460, 25509,\n",
       "          6460, 19839,  3449, 19506, 26494, 24317,  2050, 11463, 20897,  1516,\n",
       "         19330, 12044, 12707,  2080, 19607,  2319, 11721, 12821,  2310,  6290,\n",
       "         13340,  2480, 20697,  2080, 12849, 20058, 12380,  2099,  3900,  1037,\n",
       "          1043,  7677,  2869,  6460, 16136,  2229, 10609,  1012, 12849, 12638,\n",
       "          2484,  1055,  4143, 16739,  5937, 12902,  7861,  2884,  8126,  6582,\n",
       "          1037, 16137,  7716,  5480, 11265,  6292, 14728, 26493,  2368,  1037,\n",
       "         20105,  2022, 19510, 12260,  1010, 12669, 19531,  2094,  3567,  1037,\n",
       "         17613,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10\n",
    "\n",
    "def create_dataloader(df, tokenizer, max_token_len, batch_size):\n",
    "    dataset = ArticleDataset(\n",
    "        df,\n",
    "        tokenizer=tokenizer,\n",
    "        max_token_len=max_token_len\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = create_dataloader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "data_loader_test = create_dataloader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "data_loader_eval = create_dataloader(df_eval, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 2 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     17\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/bert/modeling_bert.py:1597\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1596\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1597\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1599\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 2 is out of bounds."
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "EPOCHS = 10\n",
    "BATC_SIZE = 8\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader_train:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels.squeeze())\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m eval_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m correct_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss = 0\n",
    "correct_labels = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader_eval:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        eval_loss += loss.item()\n",
    "        correct_labels += (logits.argmax(1) == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
